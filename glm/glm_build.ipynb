{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from scipy import stats\n",
    "plt.rc(\"figure\", figsize=(16,8))\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/modelling.csv')\n",
    "holdout_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/holdout.csv')\n",
    "kaggle_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160001, 116)\n",
      "(28317, 116)\n",
      "(125546, 131)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(holdout_df.shape)\n",
    "print(kaggle_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling dataset rows:\t 112001\n",
      "Validation dataset rows:\t 48000\n"
     ]
    }
   ],
   "source": [
    "def training_validation_subset(df):\n",
    "    ''' function to create training and validation subsets\n",
    "        chosen this methodology as a method to replicate in the future '''\n",
    "\n",
    "    training_df = df.sample(frac=0.7)\n",
    "    print('Modelling dataset rows:\\t', training_df.shape[0])\n",
    "\n",
    "    validation_df = pd.concat([df, training_df]).drop_duplicates(keep=False)\n",
    "    print('Validation dataset rows:\\t', validation_df.shape[0])\n",
    "\n",
    "    return training_df, validation_df\n",
    "\n",
    "modelling_df, validation_df=training_validation_subset(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_outlier_capping(df, variable, multiplier):\n",
    "\n",
    "    ''' windsorise the response variable '''\n",
    "\n",
    "    q1 = np.percentile(df[variable],25)\n",
    "    q3 = np.percentile(df[variable],75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - (iqr * multiplier)\n",
    "    upper = q3 + (iqr * multiplier)\n",
    "\n",
    "    df[variable] = np.where(df[variable]<=lower, lower, df[variable])\n",
    "    df[variable] = np.where(df[variable]>=upper, upper, df[variable])\n",
    "\n",
    "    return df\n",
    "\n",
    "def log_response(df, response):\n",
    "\n",
    "    ''' take the natural log of the response variable '''\n",
    "\n",
    "    print('Skewness of untransformed response:\\t' + str(df[response].skew()))\n",
    "\n",
    "    # transform response column to ensure +ve\n",
    "    minimum_val = math.ceil(min(abs(np.log(df[response]))))\n",
    "    original_data = np.log(df[response]) + minimum_val\n",
    "    df[response] = np.log(df[response])\n",
    "    print('Skewness of transformed response:\\t' + str(df[response].skew()))\n",
    "\n",
    "    return df\n",
    "\n",
    "modelling_df=response_outlier_capping(modelling_df, 'loss', 2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_categoric_columns(df):\n",
    "    \n",
    "    ''' function to return categoric columns '''\n",
    "\n",
    "    all_columns = list(df.columns)\n",
    "    numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'uint8']\n",
    "    numeric_columns = df.select_dtypes(include=numeric_types).columns.to_list()\n",
    "    categoric_columns = list(set(all_columns) - set(numeric_columns))\n",
    "    return categoric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_bin_cols(df, threshold):\n",
    "    \n",
    "    ''' function to group up values with low frequency based on a specified threshold'''\n",
    "\n",
    "    # empty lists\n",
    "    fe_cols=[]\n",
    "    fe_transform=[]\n",
    "\n",
    "    for i in categoric_columns:\n",
    "\n",
    "        if len(df[i].unique())>=8:\n",
    "\n",
    "            fe_cols.append(i)\n",
    "            fe_transform.append(df[i].map(df.groupby(i)[i].size().sort_values(ascending=False).div(len(df)).cumsum().le(threshold)))\n",
    "\n",
    "    for u, v in zip(fe_cols, fe_transform):\n",
    "        \n",
    "        df[u] = np.where(v, df[u], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_columns=return_categoric_columns(modelling_df)\n",
    "frequency_bin_cols(modelling_df, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_transformer(df1, df2, col):\n",
    "\n",
    "    ''' function to transform datasets to match '''\n",
    "    \n",
    "    list1=list(sorted(df1[col].unique()))\n",
    "    list2=list(sorted(df2[col].unique()))\n",
    "\n",
    "    intersection=list(set(list1).intersection(list2))\n",
    "\n",
    "    df2[col]=np.where(df2[col].isin(intersection),df2[col],'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categoric_columns:\n",
    "    frequency_transformer(modelling_df, validation_df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part can be improved by automating the glm build, e.g. https://planspace.org/20150423-forward_selection_with_statsmodels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glm_iteration(df, starting_formula, iterable_cols):\n",
    "    \n",
    "    ''' function to build the an intertion of a glm '''\n",
    "\n",
    "    column=[]\n",
    "    formulas=[]\n",
    "    pvalues=[]\n",
    "\n",
    "    for i in iterable_cols:\n",
    "\n",
    "        formula=starting_formula\n",
    "\n",
    "        if i in (return_categoric_columns(df)):\n",
    "\n",
    "            column.append(i)\n",
    "            formula=formula+'C('+i+')'\n",
    "            formulas.append(formula)\n",
    "            glm_gamma = smf.glm(formula=formula, data=df, family=sm.families.Gamma(sm.families.links.log()))\n",
    "            glm_results = glm_gamma.fit()\n",
    "            pvalues.append(list(glm_results.pvalues)[-1])\n",
    "\n",
    "        else: \n",
    "\n",
    "            column.append(i)\n",
    "            formula=formula+i\n",
    "            formulas.append(formula)\n",
    "            glm_gamma = smf.glm(formula=formula, data=df, family=sm.families.Gamma(sm.families.links.log()))\n",
    "            glm_results = glm_gamma.fit()\n",
    "            pvalues.append(list(glm_results.pvalues)[-1])\n",
    "\n",
    "    min_pvalue_index=pvalues.index(min(pvalues))\n",
    "    fitted_factor=column[min_pvalue_index]\n",
    "    fitted_formula=formulas[min_pvalue_index]\n",
    "    fitted_pvalue=pvalues[min_pvalue_index]\n",
    "            \n",
    "    return fitted_factor,fitted_formula,fitted_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_glm(df, starting_formula, iterable_cols):\n",
    "    \n",
    "    ''' function to build many glm models and continue adding variables based on p values '''\n",
    "    \n",
    "    fitted_factor,fitted_formula,fitted_pvalue=glm_iteration(df, starting_formula, iterable_cols)\n",
    "    print(fitted_factor,fitted_formula,fitted_pvalue)\n",
    "\n",
    "    for i in range(0,len(iterable_cols)-1):\n",
    "        \n",
    "        while fitted_pvalue<=0.05:\n",
    "        \n",
    "            iteration_formula=fitted_formula+'+'\n",
    "            iterable_cols.remove(fitted_factor)\n",
    "            fitted_factor,fitted_formula,fitted_pvalue=glm_iteration(df, iteration_formula, iterable_cols)\n",
    "            print(fitted_factor,fitted_formula,fitted_pvalue)\n",
    "    \n",
    "    best_formula=fitted_formula.replace('+'+fitted_factor, \"\")\n",
    "    return best_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat1 y~C(cat1) 0.0\n",
      "cat10 y~C(cat1)+C(cat10) 0.0\n",
      "cont2 y~C(cat1)+C(cat10)+cont2 1.509188610284137e-300\n",
      "cat104 y~C(cat1)+C(cat10)+cont2+C(cat104) 0.0\n",
      "cat100 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100) 0.0\n",
      "cont7 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7 5.9766667931805126e-238\n",
      "cont3 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3 1.1028072507200276e-35\n",
      "cont14 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14 1.0831188147565186e-32\n",
      "cont4 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4 4.980649168784691e-07\n",
      "cont8 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4+cont8 2.3047210160066206e-13\n",
      "cont12 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4+cont8+cont12 3.067013911637932e-08\n",
      "cont10 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4+cont8+cont12+cont10 1.740914905701353e-14\n",
      "cont9 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4+cont8+cont12+cont10+cont9 1.289490178285073e-08\n",
      "cont1 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4+cont8+cont12+cont10+cont9+cont1 2.271930498843597e-20\n",
      "cont13 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4+cont8+cont12+cont10+cont9+cont1+cont13 1.9664782804082386e-11\n",
      "cont5 y~C(cat1)+C(cat10)+cont2+C(cat104)+C(cat100)+cont7+cont3+cont14+cont4+cont8+cont12+cont10+cont9+cont1+cont13+cont5 0.17854359372195494\n"
     ]
    }
   ],
   "source": [
    "removal_cols=['id', 'loss']\n",
    "X=modelling_df.drop(removal_cols, axis=1)\n",
    "y=np.log(modelling_df['loss'])\n",
    "iterable_cols = list(X[X.columns[0:18]])\n",
    "starting_formula='y~'\n",
    "modelling_df\n",
    "\n",
    "best_formula = automate_glm(modelling_df, starting_formula, iterable_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_gamma = smf.glm(formula=best_formula, data=modelling_df, family=sm.families.Gamma(sm.families.links.log()))\n",
    "glm_results = glm_gamma.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  1495.2783190564853\n"
     ]
    }
   ],
   "source": [
    "X_train=modelling_df.drop(removal_cols, axis=1)\n",
    "y_pred=np.exp(glm_results.predict(X_train))\n",
    "y_valid=modelling_df['loss']\n",
    "result=mean_absolute_error(y_pred, y_valid)\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  1626.4597339043573\n"
     ]
    }
   ],
   "source": [
    "X_test=validation_df.drop(removal_cols, axis=1)\n",
    "y_pred=np.exp(glm_results.predict(X_test))\n",
    "y_valid=validation_df['loss']\n",
    "result=mean_absolute_error(y_pred, y_valid)\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_cats=return_categoric_columns(holdout_df)\n",
    "\n",
    "for i in holdout_cats:\n",
    "\n",
    "    frequency_transformer(modelling_df, holdout_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.exp(glm_results.predict(holdout_df))\n",
    "idx=holdout_df['id']\n",
    "d = {'id':idx,'glm_pred':y_pred}\n",
    "out_df=pd.DataFrame(d)\n",
    "out_df.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/holdout_glm_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_cats=return_categoric_columns(kaggle_df)\n",
    "\n",
    "for i in holdout_cats:\n",
    "\n",
    "    frequency_transformer(modelling_df, kaggle_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.exp(glm_results.predict(kaggle_df))\n",
    "idx=kaggle_df['id']\n",
    "d = {'id':idx,'loss':y_pred}\n",
    "out_df=pd.DataFrame(d)\n",
    "out_df.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/kaggle_glm_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=glm_results.params.to_frame().reset_index()\n",
    "params.columns=['level', 'coef']\n",
    "params.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/glm_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:735: RuntimeWarning: invalid value encountered in log\n",
      "  ll_obs -= special.gammaln(weight_scale) + np.log(endog)\n"
     ]
    }
   ],
   "source": [
    "glm_results.summary().as_csv()\n",
    "\n",
    "results_summary = glm_results.summary()\n",
    "\n",
    "# Note that tables is a list. The table at index 1 is the \"core\" table. Additionally, read_html puts dfs in a list, so we want index 0\n",
    "results_as_html = results_summary.tables[1].as_html()\n",
    "\n",
    "with open(\"/Users/Ben/Desktop/optimal_decision_trees/outputs/glm_summary.html\", \"w\") as file:\n",
    "    file.write(results_as_html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
