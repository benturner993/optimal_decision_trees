{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from scipy import stats\n",
    "plt.rc(\"figure\", figsize=(16,8))\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/modelling.csv')\n",
    "holdout_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/holdout.csv')\n",
    "kaggle_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160001, 116)\n",
      "(28317, 116)\n",
      "(125546, 131)\n"
     ]
    }
   ],
   "source": [
    "print(training_df.shape)\n",
    "print(holdout_df.shape)\n",
    "print(kaggle_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scoring_cols(df1, df2):\n",
    "    \n",
    "#     ''' function to compare the levels in two dataframes and return the columns which align '''\n",
    "\n",
    "#     # find categoric columns\n",
    "#     all_columns = list(df2.columns)\n",
    "#     numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'uint8']\n",
    "#     numeric_columns = df2.select_dtypes(include=numeric_types).columns.to_list()\n",
    "#     categoric_columns = list(set(all_columns) - set(numeric_columns))\n",
    "\n",
    "#     # create empty list for columns and indicators\n",
    "#     cols=[]\n",
    "#     cols_ind=[]\n",
    "\n",
    "#     # loop through all categoric columns and create indicators\n",
    "#     for i in categoric_columns:\n",
    "#         df_t_unique=sorted(df1[i].unique())\n",
    "#         df_te_unique=sorted(df2[i].unique())\n",
    "#         cols.append(i)\n",
    "#         cols_ind.append(df_t_unique==df_te_unique)\n",
    "\n",
    "#     # filter for relevant columns\n",
    "#     d = {'cols':cols,'cols_ind':cols_ind}\n",
    "#     df = pd.DataFrame(d)\n",
    "#     cat_cols=df.loc[df['cols_ind']==True]['cols']\n",
    "\n",
    "#     # combine with numerics and add loss\n",
    "#     modelling_cols = numeric_columns + sorted(list(cat_cols))\n",
    "#     modelling_cols.append('loss')\n",
    "\n",
    "#     return modelling_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring_cols=scoring_cols(training_df, kaggle_df)\n",
    "# training_df=training_df[scoring_cols]\n",
    "\n",
    "# # create training df\n",
    "# train_df=training_df.loc[training_df.index<=160000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predictors_ordinal_encoding(df):\n",
    "\n",
    "#     ''' one hot encode categorical features '''\n",
    "\n",
    "#     # find all relevant columns\n",
    "#     all_columns = list(df.columns)\n",
    "#     numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'uint8']\n",
    "#     numeric_columns = df.select_dtypes(include=numeric_types).columns.to_list()\n",
    "#     categoric_columns = list(set(all_columns) - set(numeric_columns))\n",
    "    \n",
    "#     # Encoding make column using LabelEncoder\n",
    "#     labelencoder = LabelEncoder()\n",
    "\n",
    "#     for i in categoric_columns:\n",
    "#         df[i + '_ord'] = labelencoder.fit_transform(df[i])\n",
    "\n",
    "#     # remove categoric cols\n",
    "#     numeric_columns = df.select_dtypes(include=numeric_types).columns.to_list()\n",
    "#     df = df[numeric_columns]\n",
    "\n",
    "#     return df\n",
    "\n",
    "# def response_outlier_capping(df, variable, multiplier):\n",
    "\n",
    "#     ''' windsorise the response variable '''\n",
    "\n",
    "#     q1 = np.percentile(df[variable],25)\n",
    "#     q3 = np.percentile(df[variable],75)\n",
    "#     iqr = q3 - q1\n",
    "#     lower = q1 - (iqr * multiplier)\n",
    "#     upper = q3 + (iqr * multiplier)\n",
    "\n",
    "#     df[variable] = np.where(df[variable]<=lower, lower, df[variable])\n",
    "#     df[variable] = np.where(df[variable]>=upper, upper, df[variable])\n",
    "\n",
    "#     return df\n",
    "\n",
    "# def log_response(df, response):\n",
    "\n",
    "#     ''' take the natural log of the response variable '''\n",
    "\n",
    "#     print('Skewness of untransformed response:\\t' + str(df[response].skew()))\n",
    "\n",
    "#     # transform response column to ensure +ve\n",
    "#     minimum_val = math.ceil(min(abs(np.log(df[response]))))\n",
    "#     original_data = np.log(df[response]) + minimum_val\n",
    "#     df[response] = np.log(df[response])\n",
    "#     print('Skewness of transformed response:\\t' + str(df[response].skew()))\n",
    "\n",
    "#     return df\n",
    "\n",
    "# training_df=response_outlier_capping(training_df, 'loss', 2.2)\n",
    "# training_df=log_response(training_df, 'loss')\n",
    "# training_df = predictors_ordinal_encoding(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling dataset rows:\t 112001\n",
      "Validation dataset rows:\t 48000\n"
     ]
    }
   ],
   "source": [
    "def training_validation_subset(df):\n",
    "    ''' function to create training and validation subsets\n",
    "        chosen this methodology as a method to replicate in the future '''\n",
    "\n",
    "    training_df = df.sample(frac=0.7)\n",
    "    print('Modelling dataset rows:\\t', training_df.shape[0])\n",
    "\n",
    "    validation_df = pd.concat([df, training_df]).drop_duplicates(keep=False)\n",
    "    print('Validation dataset rows:\\t', validation_df.shape[0])\n",
    "\n",
    "    return training_df, validation_df\n",
    "\n",
    "modelling_df, validation_df=training_validation_subset(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part can be improved by automating the glm build, e.g. https://planspace.org/20150423-forward_selection_with_statsmodels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat87</th>\n",
       "      <th>cat88</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58574</th>\n",
       "      <td>183579</td>\n",
       "      <td>0.546670</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.728827</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.364464</td>\n",
       "      <td>0.401162</td>\n",
       "      <td>0.26847</td>\n",
       "      <td>0.46226</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>766.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37017</th>\n",
       "      <td>116084</td>\n",
       "      <td>0.513457</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.549770</td>\n",
       "      <td>0.594598</td>\n",
       "      <td>0.405415</td>\n",
       "      <td>0.416181</td>\n",
       "      <td>0.402349</td>\n",
       "      <td>0.62918</td>\n",
       "      <td>0.50630</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>2075.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75915</th>\n",
       "      <td>237425</td>\n",
       "      <td>0.472892</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.634224</td>\n",
       "      <td>0.844287</td>\n",
       "      <td>0.682110</td>\n",
       "      <td>0.385129</td>\n",
       "      <td>0.333632</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>0.50630</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>2105.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     cont1     cont2     cont3     cont4     cont5     cont6  \\\n",
       "58574  183579  0.546670  0.681761  0.728827  0.373816  0.718531  0.364464   \n",
       "37017  116084  0.513457  0.681761  0.549770  0.594598  0.405415  0.416181   \n",
       "75915  237425  0.472892  0.620805  0.634224  0.844287  0.682110  0.385129   \n",
       "\n",
       "          cont7    cont8    cont9  ...  cat87  cat88  cat9  cat91  cat93  \\\n",
       "58574  0.401162  0.26847  0.46226  ...      B      A     A      A      D   \n",
       "37017  0.402349  0.62918  0.50630  ...      B      A     A      C      D   \n",
       "75915  0.333632  0.58354  0.50630  ...      B      A     B      G      D   \n",
       "\n",
       "      cat94 cat95 cat97 cat98     loss  \n",
       "58574     D     D     C     A   766.30  \n",
       "37017     D     D     C     A  2075.72  \n",
       "75915     D     D     C     A  2105.70  \n",
       "\n",
       "[3 rows x 116 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelling_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'loss', 'cat104', 'cat115', 'cat107', 'cat75']\n"
     ]
    }
   ],
   "source": [
    "# find all relevant columns\n",
    "df=training_df\n",
    "all_columns = list(df.columns)\n",
    "numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'uint8']\n",
    "numeric_columns = df.select_dtypes(include=numeric_types).columns.to_list()\n",
    "categoric_columns = list(set(all_columns) - set(numeric_columns))\n",
    "\n",
    "removal_cols=['id', 'loss'] # ['id', 'loss', 'cat107', 'cat112', 'cat115']\n",
    "\n",
    "for i in categoric_columns:\n",
    "    \n",
    "    if len(list(set(modelling_df[i].unique())-set(validation_df[i].unique())))>0:\n",
    "        \n",
    "        removal_cols.append(i)\n",
    "        \n",
    "for i in categoric_columns:\n",
    "    \n",
    "    if len(list(set(validation_df[i].unique())-set(modelling_df[i].unique())))>0:\n",
    "        \n",
    "        removal_cols.append(i)\n",
    "        \n",
    "print(removal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=modelling_df.drop(removal_cols, axis=1)\n",
    "y=np.log(modelling_df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_formula(X):\n",
    "\n",
    "    full_cols=[]\n",
    "    formula='y~'\n",
    "\n",
    "    for u, i in enumerate(list(X.columns)):\n",
    "        if u==0:\n",
    "\n",
    "            if X[i].dtype==np.float64:\n",
    "                full_cols.append(i)\n",
    "                formula=formula+i\n",
    "            else:\n",
    "                full_cols.append('C('+i+')')\n",
    "                formula=formula+'C('+i+')'\n",
    "\n",
    "        else:\n",
    "\n",
    "            if X[i].dtype==np.float64:\n",
    "                full_cols.append(i)\n",
    "                formula=formula+'+'+i\n",
    "            else:\n",
    "                full_cols.append('+C('+i+')')\n",
    "                formula=formula+'+C('+i+')'\n",
    "                \n",
    "    return formula\n",
    "\n",
    "formula=create_formula(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_gamma = smf.glm(formula=formula, data=modelling_df, family=sm.families.Gamma(sm.families.links.log()))\n",
    "glm_results = glm_gamma.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  1307.919228007923\n"
     ]
    }
   ],
   "source": [
    "X_train=modelling_df.drop(removal_cols, axis=1)\n",
    "y_pred=np.exp(glm_results.predict(X_train))\n",
    "y_valid=modelling_df['loss']\n",
    "result=mean_absolute_error(y_pred, y_valid)\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  1310.6240824816023\n"
     ]
    }
   ],
   "source": [
    "X_test=validation_df.drop(removal_cols, axis=1)\n",
    "y_pred=np.exp(glm_results.predict(X_test))\n",
    "y_valid=validation_df['loss']\n",
    "result=mean_absolute_error(y_pred, y_valid)\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_cols = list(glm_results.pvalues.where(glm_results.pvalues<=0.05).dropna().index)\n",
    "significant_cols.remove('Intercept')\n",
    "\n",
    "second_iteration_cols=[]\n",
    "\n",
    "for i in significant_cols:\n",
    "    i=i.replace(\"C(\", \"\")\n",
    "    i=i.replace('B',\"A\")\n",
    "    i=i.replace('C',\"A\")\n",
    "    i=i.replace('D',\"A\")\n",
    "    i=i.replace('E',\"A\")\n",
    "    i=i.replace('F',\"A\")\n",
    "    i=i.replace('G',\"A\")\n",
    "    i=i.replace('H',\"A\")\n",
    "    i=i.replace('I',\"A\")\n",
    "    i=i.replace('J',\"A\")\n",
    "    i=i.replace('K',\"A\")\n",
    "    i=i.replace('L',\"A\")\n",
    "    i=i.replace('M',\"A\")\n",
    "    i=i.replace('N',\"A\")\n",
    "    i=i.replace('O',\"A\")\n",
    "    i=i.replace('P',\"A\")\n",
    "    i=i.replace('Q',\"A\")\n",
    "    i=i.replace('R',\"A\")\n",
    "    i=i.replace('S',\"A\")\n",
    "    i=i.replace('T',\"A\")\n",
    "    i=i.replace('U',\"A\")\n",
    "    i=i.replace('V',\"A\")\n",
    "    i=i.replace('W',\"A\")\n",
    "    i=i.replace('X',\"A\")\n",
    "    i=i.replace('Y',\"A\")\n",
    "    i=i.replace('Z',\"A\")\n",
    "    i=i.replace(')[A.A]',\"\")\n",
    "    i=i.replace(')[A.AA]',\"\")\n",
    "    second_iteration_cols.append(i)\n",
    "    \n",
    "second_iteration_cols=set(second_iteration_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=modelling_df.drop(removal_cols, axis=1)\n",
    "y=np.log(modelling_df['loss'])\n",
    "\n",
    "X=X[second_iteration_cols]\n",
    "\n",
    "formula=create_formula(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_gamma = smf.glm(formula=formula, data=modelling_df, family=sm.families.Gamma(sm.families.links.log()))\n",
    "glm_results = glm_gamma.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  1366.5758856085265\n"
     ]
    }
   ],
   "source": [
    "X_test=validation_df[second_iteration_cols]\n",
    "y_pred=np.exp(glm_results.predict(X_test))\n",
    "y_valid=validation_df['loss']\n",
    "result=mean_absolute_error(y_pred, y_valid)\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout=holdout_df[second_iteration_cols]\n",
    "y_pred=np.exp(glm_results.predict(X_holdout))\n",
    "idx=holdout_df['id']\n",
    "d = {'id':idx,'glm_pred':y_pred}\n",
    "out_df=pd.DataFrame(d)\n",
    "out_df.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/holdout_glm_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle=kaggle_df[second_iteration_cols]\n",
    "y_pred=np.exp(glm_results.predict(X_kaggle))\n",
    "idx=kaggle_df['id']\n",
    "d = {'id':idx,'loss':y_pred}\n",
    "out_df=pd.DataFrame(d)\n",
    "out_df.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/kaggle_glm_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=glm_results.params.to_frame().reset_index()\n",
    "params.columns=['level', 'coef']\n",
    "params.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/glm_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_results.summary().as_csv()\n",
    "\n",
    "results_summary = glm_results.summary()\n",
    "\n",
    "# Note that tables is a list. The table at index 1 is the \"core\" table. Additionally, read_html puts dfs in a list, so we want index 0\n",
    "results_as_html = results_summary.tables[1].as_html()\n",
    "\n",
    "with open(\"/Users/Ben/Desktop/optimal_decision_trees/outputs/glm_summary.html\", \"w\") as file:\n",
    "    file.write(results_as_html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
