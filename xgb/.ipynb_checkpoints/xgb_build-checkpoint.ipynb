{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import strftime, gmtime\n",
    "\n",
    "from data import load_data\n",
    "from data_partitioning import training_validation_subset\n",
    "from data_transformation import response_outlier_capping, log_response, predictors_one_hot_encoding, \\\n",
    "    store_scaling_values, scale_numerics\n",
    "from modelling import bayes_cv_tuner, status_print, save_model\n",
    "from prediction import scores_and_fe, predict_test, predict_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded settings\n",
    "current_time = strftime(\"%Y%m%d%H%M%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded...\n",
      "Training dataset rows:\t 112001\n",
      "Validation dataset rows:\t 48000\n",
      "dataset partitioned...\n",
      "Skewness of untransformed response:\t1.4034834204419933\n",
      "Skewness of transformed response:\t-0.05365102133980038\n",
      "dataset encoded...\n",
      "feature set selected...\n",
      "Model #1\n",
      "Best Result: -0.453\n",
      "Best params: OrderedDict([('colsample_bylevel', 0.4160029192647807), ('colsample_bytree', 0.7304484857455519), ('gamma', 0.24877801005599337), ('learning_rate', 0.042815319280763466), ('max_delta_step', 13), ('max_depth', 21), ('min_child_weight', 2), ('n_estimators', 87), ('reg_alpha', 5.497557739289786e-07), ('subsample', 0.6513136724634089)])\n",
      "\n",
      "Model #2\n",
      "Best Result: -0.4266\n",
      "Best params: OrderedDict([('colsample_bylevel', 0.8390144719977516), ('colsample_bytree', 0.8844821246070537), ('gamma', 5.378869267509367e-07), ('learning_rate', 0.7988179462781242), ('max_delta_step', 17), ('max_depth', 3), ('min_child_weight', 1), ('n_estimators', 68), ('reg_alpha', 0.0005266983003701547), ('subsample', 0.9539453486878958)])\n",
      "\n",
      "Model #3\n",
      "Best Result: -0.4266\n",
      "Best params: OrderedDict([('colsample_bylevel', 0.8390144719977516), ('colsample_bytree', 0.8844821246070537), ('gamma', 5.378869267509367e-07), ('learning_rate', 0.7988179462781242), ('max_delta_step', 17), ('max_depth', 3), ('min_child_weight', 1), ('n_estimators', 68), ('reg_alpha', 0.0005266983003701547), ('subsample', 0.9539453486878958)])\n",
      "\n",
      "Model #4\n",
      "Best Result: -0.4259\n",
      "Best params: OrderedDict([('colsample_bylevel', 0.8142720284737898), ('colsample_bytree', 0.1801528457825951), ('gamma', 0.00024122576791788593), ('learning_rate', 0.4032083917998946), ('max_delta_step', 10), ('max_depth', 5), ('min_child_weight', 4), ('n_estimators', 94), ('reg_alpha', 0.1611980387486336), ('subsample', 0.3929273115755069)])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor (max_workers=64) as executor:\n",
    "\n",
    "    # load data\n",
    "    training_df, holdout_df, test_df = load_data()\n",
    "    print('dataset loaded...')\n",
    "\n",
    "    # data partitioning\n",
    "    training_df, validation_df=training_validation_subset(training_df)\n",
    "    print('dataset partitioned...')\n",
    "\n",
    "    # encode features\n",
    "    training_df=predictors_one_hot_encoding(training_df)\n",
    "    training_df=response_outlier_capping(training_df, 'loss', 2.2)\n",
    "    training_df=log_response(training_df, 'loss')\n",
    "    store_scaling_values(training_df)\n",
    "    scale_numerics(training_df)\n",
    "    print('dataset encoded...')\n",
    "\n",
    "    # feature set\n",
    "    X=training_df.drop(['id', 'loss'], axis=1)\n",
    "    y=training_df['loss']\n",
    "    print('feature set selected...')\n",
    "\n",
    "    # fit (and save) the model\n",
    "    xgb_bo = bayes_cv_tuner.fit(X, y, callback=status_print)\n",
    "    save_model(xgb_bo.best_estimator_,current_time)\n",
    "    print('modelling complete...')\n",
    "\n",
    "    # scores and feature importance\n",
    "    scores_and_fe(X, y, training_df, validation_df, xgb_bo.best_estimator_, current_time)\n",
    "    print('modelling scores created...')\n",
    "\n",
    "    # predict on test and holdout dataset\n",
    "    predict_test(training_df, test_df, xgb_bo.best_estimator_, current_time)\n",
    "    predict_holdout(training_df, holdout_df, xgb_bo.best_estimator_, current_time)\n",
    "    print('predictions complete...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
