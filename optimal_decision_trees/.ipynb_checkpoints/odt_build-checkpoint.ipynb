{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from scipy import stats\n",
    "plt.rc(\"figure\", figsize=(160,80))\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpretableai import iai\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/modelling.csv')\n",
    "kaggle_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/test.csv')\n",
    "holdout_df=pd.read_csv('/Users/Ben/Desktop/optimal_decision_trees/data/holdout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # frequency binning\n",
    "# threshold = 0.7\n",
    "# m = df['city'].map(df.groupby('city')['city'].size().sort_values(ascending=False).div(len(df)).cumsum().le(threshold))\n",
    "\n",
    "# df['city'] = np.where(m, df['city'], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_cols(df1, df2):\n",
    "    \n",
    "    ''' function to compare the levels in two dataframes and return the columns which align '''\n",
    "\n",
    "    # find categoric columns\n",
    "    all_columns = list(df2.columns)\n",
    "    numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'uint8']\n",
    "    numeric_columns = df2.select_dtypes(include=numeric_types).columns.to_list()\n",
    "    categoric_columns = list(set(all_columns) - set(numeric_columns))\n",
    "\n",
    "    # create empty list for columns and indicators\n",
    "    cols=[]\n",
    "    cols_ind=[]\n",
    "\n",
    "    # loop through all categoric columns and create indicators\n",
    "    for i in categoric_columns:\n",
    "        df_t_unique=sorted(df1[i].unique())\n",
    "        df_te_unique=sorted(df2[i].unique())\n",
    "        cols.append(i)\n",
    "        cols_ind.append(df_t_unique==df_te_unique)\n",
    "\n",
    "    # filter for relevant columns\n",
    "    d = {'cols':cols,'cols_ind':cols_ind}\n",
    "    df = pd.DataFrame(d)\n",
    "    cat_cols=df.loc[df['cols_ind']==True]['cols']\n",
    "\n",
    "    # combine with numerics and add loss\n",
    "    modelling_cols = numeric_columns + sorted(list(cat_cols))\n",
    "    modelling_cols.append('loss')\n",
    "\n",
    "    return modelling_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring_cols=scoring_cols(training_df, kaggle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_validation_subset(df):\n",
    "    ''' function to create training and validation subsets\n",
    "        chosen this methodology as a method to replicate in the future '''\n",
    "\n",
    "    training_df = df.sample(frac=0.7)\n",
    "    print('Modelling dataset rows:\\t', training_df.shape[0])\n",
    "\n",
    "    validation_df = pd.concat([df, training_df]).drop_duplicates(keep=False)\n",
    "    print('Validation dataset rows:\\t', validation_df.shape[0])\n",
    "\n",
    "    return training_df, validation_df\n",
    "\n",
    "# train_df=training_df.loc[training_df.index<=160000]\n",
    "# modelling_df, validation_df=training_validation_subset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_encoding(df):\n",
    "\n",
    "    # find all relevant columns\n",
    "    all_columns = list(df.columns)\n",
    "    numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'uint8']\n",
    "    numeric_columns = df.select_dtypes(include=numeric_types).columns.to_list()\n",
    "    categoric_columns = list(set(all_columns) - set(numeric_columns))\n",
    "\n",
    "    for i in categoric_columns:\n",
    "        df[i] = df[i].astype('category')\n",
    "        \n",
    "categorical_encoding(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group up categoric values with many levels\n",
    "# look for cols with many levels\n",
    "# group up based on response \n",
    "# segment into n levels / groups\n",
    "\n",
    "# or frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a GridSearch to fit an OptimalTreeRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(df.columns)\n",
    "X = df.loc[:, ~df.columns.isin(['loss', 'id'])]\n",
    "y = np.log(df['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = iai.split_data('regression', X, y,\n",
    "                                                      train_proportion=0.75,\n",
    "                                                      seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to choose a starting value for regression_lambda. You can either use the default value, or find a good starting estimate yourself.\n",
    "# One approach to doing this yourself cheaply is to validate over regression_lambda with max_depth fixed to zero - this is effectively just fitting a linear regression to the data and allows you to find a good baseline level of regularization:\n",
    "\n",
    "# grid = iai.GridSearch(\n",
    "#     iai.OptimalTreeRegressor(\n",
    "#         random_seed=2,\n",
    "#         max_depth=0,\n",
    "#         #regression_sparsity=:all,\n",
    "#     ),\n",
    "#     regression_lambda=[0.0001, 0.001, 0.01, 0.1],\n",
    "# )\n",
    "# iai.fit!(grid, X, y)\n",
    "# starting_lambda = IAI.get_best_params(grid)[:regression_lambda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the starting estimate from Step 1 for regression_lambda, we now tune max_depth:\n",
    "\n",
    "# grid = IAI.GridSearch(\n",
    "#     IAI.OptimalTreeRegressor(\n",
    "#         random_seed=1,\n",
    "#         regression_sparsity=:all,\n",
    "#         regression_lambda=starting_lambda,\n",
    "#     ),\n",
    "#     max_depth=1:3,\n",
    "# )\n",
    "# IAI.fit!(grid, X, y)\n",
    "# best_depth = IAI.get_best_params(grid)[:max_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we fix max_depth to the value found in Step 2, and tune regression_lambda to get the final result:\n",
    "\n",
    "# grid = IAI.GridSearch(\n",
    "#     IAI.OptimalTreeRegressor(\n",
    "#         random_seed=1,\n",
    "#         max_depth=best_depth,\n",
    "#         regression_sparsity=:all,\n",
    "#     ),\n",
    "#     regression_lambda=[0.0001, 0.001, 0.01, 0.1],\n",
    "# )\n",
    "# IAI.fit!(grid, X, y)\n",
    "# IAI.get_best_params(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = iai.GridSearch(\n",
    "    iai.OptimalTreeRegressor(\n",
    "        random_seed=123,\n",
    "    ),\n",
    "    max_depth=range(1, 10),\n",
    ")\n",
    "grid.fit(train_X, train_y) # https://docs.interpretable.ai/stable/OptimalTrees/tuning/\n",
    "grid.get_learner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make predictions on new data using predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Result\n",
    "y_pred=np.exp(grid.predict(train_X))\n",
    "result=mean_absolute_error(y_pred, train_y)\n",
    "print('train result: ', result)\n",
    "\n",
    "# Test Result\n",
    "y_pred=np.exp(grid.predict(test_X))\n",
    "result=mean_absolute_error(y_pred, test_y)\n",
    "print('test result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout df\n",
    "X_test= holdout_df[cols].loc[:, ~holdout_df.columns.isin(['loss', 'id'])]\n",
    "\n",
    "# Encode\n",
    "categorical_encoding(X_test)\n",
    "\n",
    "grid.predict(X_test)\n",
    "\n",
    "y_pred=np.exp(grid.predict(X_test))\n",
    "y_valid=holdout_df['loss']\n",
    "result=mean_absolute_error(y_pred, y_valid)\n",
    "print('result: ', result)\n",
    "\n",
    "idx=holdout_df['id']\n",
    "d = {'id':idx,'loss':y_pred}\n",
    "out_df=pd.DataFrame(d)\n",
    "out_df.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/holdout_odt_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle df\n",
    "X_kaggle= kaggle_df.loc[:, ~kaggle_df.columns.isin(['id'])]\n",
    "\n",
    "# Encode\n",
    "categorical_encoding(X_kaggle)\n",
    "\n",
    "idx=kaggle_df['id']\n",
    "y_pred=np.exp(grid.predict(X_kaggle))\n",
    "d = {'id':idx,'loss':y_pred}\n",
    "out_df=pd.DataFrame(d)\n",
    "out_df.to_csv('/Users/Ben/Desktop/optimal_decision_trees/outputs/kaggle_odt_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.write_html('/Users/Ben/Desktop/optimal_decision_trees/outputs/odt_model.html')\n",
    "grid.write_json('/Users/Ben/Desktop/optimal_decision_trees/outputs/odt_model.json')\n",
    "#lnr = IAI.read_json(\"learner.json\") https://docs.interpretable.ai/stable/IAIBase/learner/#Parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
